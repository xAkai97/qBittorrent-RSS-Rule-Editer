"""
SubsPlease API integration for fetching anime schedule and titles.

IMPORTANT: This uses SubsPlease's public API responsibly with caching.
"""
import json
import logging
import os
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Union, Any

from .constants import CacheKeys
from .config import config

logger = logging.getLogger(__name__)

try:
    import requests
except ImportError:
    requests = None


def load_subsplease_cache() -> Dict[str, Dict[str, Any]]:
    """
    Loads cached SubsPlease schedule titles from cache.
    
    Returns:
        Dict with title as key and metadata dict as value:
        {
            "Anime Title": {
                "subsplease": "SubsPlease Title",
                "last_updated": "2024-01-15T10:30:00",
                "exact_match": True
            }
        }
    """
    if not os.path.exists(config.CACHE_FILE):
        return {}
    
    try:
        with open(config.CACHE_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
        cached = data.get(CacheKeys.SUBSPLEASE_TITLES, {}) or {}
        logger.info(f"Loaded {len(cached)} cached SubsPlease titles")
        return cached
    except Exception as e:
        logger.error(f"Failed to load SubsPlease cache: {e}")
        return {}


def save_subsplease_cache(titles_dict: Dict[str, Dict[str, Any]]) -> bool:
    """
    Saves SubsPlease schedule titles to cache.
    
    Args:
        titles_dict: Dictionary of titles with metadata
    
    Returns:
        bool: True if successful
    """
    try:
        from . import cache as cache_module
        success = cache_module._update_cache_key(CacheKeys.SUBSPLEASE_TITLES, titles_dict)
        if success:
            logger.info(f"Saved {len(titles_dict)} SubsPlease titles to cache")
        return success
    except Exception as e:
        logger.error(f"Failed to save SubsPlease cache: {e}")
        return False


def fetch_subsplease_schedule(force_refresh: bool = False) -> Tuple[bool, Union[List[str], str]]:
    """
    Fetches current anime titles from SubsPlease API.
    
    Uses the SubsPlease API (https://subsplease.org/api/?f=schedule&tz=UTC) 
    to get the current season's anime schedule and extract all show titles.
    
    IMPORTANT: This uses SubsPlease's public API. Usage notes:
    - SubsPlease has no published terms restricting API access
    - Multiple open-source projects use this API
    - Rate limiting is handled through caching
    - Proper User-Agent headers identify the application
    
    Args:
        force_refresh: If True, fetches from API even if cache exists
    
    Returns:
        Tuple[bool, Union[List[str], str]]: (success, list_of_titles or error_message)
    """
    if not requests:
        return False, "requests library not available"
    
    # Check cache first unless force refresh
    if not force_refresh:
        cached = load_subsplease_cache()
        if cached:
            titles = list(cached.keys())
            logger.info(f"Using cached SubsPlease titles: {len(titles)} entries")
            return True, titles
    
    try:
        # Use SubsPlease API instead of scraping HTML
        url = "https://subsplease.org/api/?f=schedule&tz=UTC"
        logger.info(f"Fetching SubsPlease schedule from API: {url}")
        
        # Add proper headers to identify the application
        headers = {
            'User-Agent': 'qBittorrent-RSS-Rule-Editor/1.0 (https://github.com/xAkai97/qBittorrent-RSS-Rule-Editer)',
            'Accept': 'application/json'
        }
        
        response = requests.get(url, timeout=10, headers=headers)
        response.raise_for_status()
        
        # Parse JSON response
        data = response.json()
        
        if not isinstance(data, dict) or 'schedule' not in data:
            return False, "Invalid API response format"
        
        # Extract titles from all days
        titles = []
        schedule = data['schedule']
        
        for day, shows in schedule.items():
            if isinstance(shows, list):
                for show in shows:
                    if isinstance(show, dict):
                        title = show.get('title', '').strip()
                        if title and title not in titles:
                            titles.append(title)
        
        if not titles:
            return False, "No titles found in API response"
        
        # Cache the results with timestamp
        timestamp = datetime.now().isoformat()
        cache_dict = {}
        for title in titles:
            cache_dict[title] = {
                "subsplease": title,
                "last_updated": timestamp,
                "exact_match": True
            }
        
        save_subsplease_cache(cache_dict)
        logger.info(f"Successfully fetched {len(titles)} titles from SubsPlease API")
        
        return True, sorted(titles)
        
    except requests.exceptions.RequestException as e:
        error_msg = f"Network error fetching SubsPlease schedule: {e}"
        logger.error(error_msg)
        return False, error_msg
    except Exception as e:
        error_msg = f"Error parsing SubsPlease schedule: {e}"
        logger.error(error_msg)
        return False, error_msg


def find_subsplease_title_match(mal_title: str) -> Optional[str]:
    """
    Finds matching SubsPlease title for a given MAL title from cache.
    
    Uses improved fuzzy matching to handle title variations like:
    - "One Punch Man 3" vs "One-Punch Man S3"
    - Different punctuation (spaces, hyphens, colons)
    - Season numbering formats (3, S3, Season 3)
    
    Args:
        mal_title: The anime title from MyAnimeList
    
    Returns:
        Optional[str]: Matching SubsPlease title or None if no match
    """
    cached = load_subsplease_cache()
    
    def normalize_title(title: str) -> str:
        """Normalize title for comparison by removing special chars and standardizing format."""
        normalized = title.lower()
        # Remove common punctuation and standardize
        normalized = normalized.replace('-', ' ').replace(':', ' ').replace('!', '').replace('?', '')
        normalized = normalized.replace('  ', ' ').strip()
        # Normalize season formats: "S3" -> "3", "season 3" -> "3"
        import re
        normalized = re.sub(r'\bs(\d+)\b', r'\1', normalized)  # S3 -> 3
        normalized = re.sub(r'\bseason\s+(\d+)\b', r'\1', normalized)  # season 3 -> 3
        return normalized
    
    # Try exact match first
    if mal_title in cached:
        match_data = cached[mal_title]
        if isinstance(match_data, dict):
            return match_data.get('subsplease', mal_title)
        return str(match_data)
    
    # Try case-insensitive match
    mal_lower = mal_title.lower()
    for cached_title, data in cached.items():
        if cached_title.lower() == mal_lower:
            if isinstance(data, dict):
                return data.get('subsplease', cached_title)
            return cached_title
    
    # Try normalized fuzzy matching
    mal_normalized = normalize_title(mal_title)
    best_match = None
    best_score = 0
    
    for cached_title, data in cached.items():
        cached_normalized = normalize_title(cached_title)
        
        # Exact normalized match (handles punctuation differences)
        if mal_normalized == cached_normalized:
            if isinstance(data, dict):
                return data.get('subsplease', cached_title)
            return cached_title
        
        # Check if one contains the other (with normalized versions)
        if mal_normalized in cached_normalized or cached_normalized in mal_normalized:
            # Calculate match score based on length similarity
            score = min(len(mal_normalized), len(cached_normalized))
            if score > best_score:
                best_score = score
                best_match = data.get('subsplease', cached_title) if isinstance(data, dict) else cached_title
    
    # Try partial word matching for multi-word titles
    if not best_match:
        mal_words = set(mal_normalized.split())
        for cached_title, data in cached.items():
            cached_words = set(normalize_title(cached_title).split())
            
            # Calculate word overlap
            common_words = mal_words & cached_words
            if len(common_words) >= 2:  # At least 2 words in common
                # Score based on percentage of words matched
                score = len(common_words) / max(len(mal_words), len(cached_words))
                if score > 0.6 and score * 100 > best_score:  # At least 60% word match
                    best_score = score * 100
                    best_match = data.get('subsplease', cached_title) if isinstance(data, dict) else cached_title
    
    return best_match
